# =============================================================================
# Mektep Scraper Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control!

# -----------------------------------------------------------------------------
# Flask Environment
# -----------------------------------------------------------------------------
# Options: development, production, testing
FLASK_ENV=development

# -----------------------------------------------------------------------------
# Security (REQUIRED in production!)
# -----------------------------------------------------------------------------
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
SECRET_KEY=dev-secret-key-change-me-in-production

# Key for encrypting displayed passwords (optional)
PASSWORD_ENC_KEY=

# -----------------------------------------------------------------------------
# Database
# -----------------------------------------------------------------------------
# Development (SQLite - default):
# DATABASE_URL=sqlite:///../instance/mektep_platform.db

# Production (PostgreSQL - recommended):
# DATABASE_URL=postgresql://user:password@localhost:5432/mektep_db

# PostgreSQL password (used by docker-compose.yml)
# Generate with: python -c "import secrets; print(secrets.token_hex(16))"
POSTGRES_PASSWORD=

# -----------------------------------------------------------------------------
# Mektep.edu.kz Credentials (for CLI scraping)
# -----------------------------------------------------------------------------
MEKTEP_LOGIN=YOUR_LOGIN_OR_IIN
MEKTEP_PASSWORD=YOUR_PASSWORD

# -----------------------------------------------------------------------------
# File Storage
# -----------------------------------------------------------------------------
# Root directory for uploaded files (relative to project root or absolute)
UPLOAD_ROOT=out/platform_uploads

# -----------------------------------------------------------------------------
# Job Processing
# -----------------------------------------------------------------------------
# Maximum number of simultaneous scraping jobs
# Each job uses ~1-2 GB RAM for Playwright browser
MAX_CONCURRENT_JOBS=3

# Maximum runtime for a single job (seconds)
# Default: 30 minutes
JOB_TIMEOUT_SECONDS=1800

# -----------------------------------------------------------------------------
# Scraper Settings
# -----------------------------------------------------------------------------
# Run browser in headless mode (1=yes, 0=show browser)
SCRAPER_HEADLESS=1

# Slow motion delay in ms (useful for debugging)
SCRAPER_SLOWMO_MS=0

# -----------------------------------------------------------------------------
# Bootstrap Admin (first run)
# -----------------------------------------------------------------------------
# Leave empty to use defaults (admin/admin123)
BOOTSTRAP_SUPERADMIN_USER=
BOOTSTRAP_SUPERADMIN_PASS=

# -----------------------------------------------------------------------------
# AI Text Generation (Qwen/DashScope)
# -----------------------------------------------------------------------------
# API key for Qwen AI text generation
# Get your key at: https://dashscope.console.aliyun.com/
DASHSCOPE_API_KEY=

# -----------------------------------------------------------------------------
# Redis (for rate limiting, caching, and Celery)
# -----------------------------------------------------------------------------
# Local development:
REDIS_URL=redis://localhost:6379/0

# Docker:
# REDIS_URL=redis://redis:6379/0

# Redis Cloud/AWS ElastiCache:
# REDIS_URL=redis://user:password@host:6379/0

# -----------------------------------------------------------------------------
# Celery (async task queue)
# -----------------------------------------------------------------------------
# Enable Celery for background jobs (requires Redis)
USE_CELERY=0

# Celery broker (defaults to REDIS_URL)
# CELERY_BROKER_URL=redis://localhost:6379/0

# Celery result backend (defaults to REDIS_URL)
# CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Number of concurrent Celery workers
CELERY_CONCURRENCY=2

# -----------------------------------------------------------------------------
# Gunicorn (production server - Unix only)
# -----------------------------------------------------------------------------
GUNICORN_BIND=0.0.0.0:5000
GUNICORN_WORKERS=4
GUNICORN_THREADS=2
GUNICORN_TIMEOUT=120
GUNICORN_LOG_LEVEL=info

# -----------------------------------------------------------------------------
# Waitress (production server - Windows compatible)
# -----------------------------------------------------------------------------
WAITRESS_HOST=0.0.0.0
WAITRESS_PORT=5000
WAITRESS_THREADS=4

# -----------------------------------------------------------------------------
# Desktop App Download
# -----------------------------------------------------------------------------
# Path to built desktop app (exe or zip) for /download/desktop
# Example: dist/Mektep Desktop/Mektep Desktop.exe
# DESKTOP_DOWNLOAD_PATH=

# Or external URL to redirect users (e.g. GitHub Releases)
# DESKTOP_DOWNLOAD_URL=https://example.com/releases/MektepDesktop.zip
